{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RashmiJK/PGP-AIML-MedicalAssistant-NLP/blob/main/medical_assistant_RAG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3CNz35ia6Bz3"
      },
      "source": [
        "## Problem Statement"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CkRbhMJH6Bz3"
      },
      "source": [
        "### Business Context"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3PBm5xaj6Bz3"
      },
      "source": [
        "The healthcare industry is rapidly evolving, with professionals facing increasing challenges in managing vast volumes of medical data while delivering accurate and timely diagnoses. The need for quick access to comprehensive, reliable, and up-to-date medical knowledge is critical for improving patient outcomes and ensuring informed decision-making in a fast-paced environment.\n",
        "\n",
        "Healthcare professionals often encounter information overload, struggling to sift through extensive research and data to create accurate diagnoses and treatment plans. This challenge is amplified by the need for efficiency, particularly in emergencies, where time-sensitive decisions are vital. Furthermore, access to trusted, current medical information from renowned manuals and research papers is essential for maintaining high standards of care.\n",
        "\n",
        "To address these challenges, healthcare centers can focus on integrating systems that streamline access to medical knowledge, provide tools to support quick decision-making, and enhance efficiency. Leveraging centralized knowledge platforms and ensuring healthcare providers have continuous access to reliable resources can significantly improve patient care and operational effectiveness."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xDPsqvO6Bz5"
      },
      "source": [
        "**Common Questions to Answer**\n",
        "\n",
        "**1. Diagnostic Assistance**: \"What are the common symptoms and treatments for pulmonary embolism?\"\n",
        "\n",
        "**2. Drug Information**: \"Can you provide the trade names of medications used for treating hypertension?\"\n",
        "\n",
        "**3. Treatment Plans**: \"What are the first-line options and alternatives for managing rheumatoid arthritis?\"\n",
        "\n",
        "**4. Specialty Knowledge**: \"What are the diagnostic steps for suspected endocrine disorders?\"\n",
        "\n",
        "**5. Critical Care Protocols**: \"What is the protocol for managing sepsis in a critical care unit?\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CARPKFwm6Bz4"
      },
      "source": [
        "### Objective"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOElOEXq6Bz4"
      },
      "source": [
        "As an AI specialist, your task is to develop a RAG-based AI solution using renowned medical manuals to address healthcare challenges. The objective is to **understand** issues like information overload, **apply** AI techniques to streamline decision-making, **analyze** its impact on diagnostics and patient outcomes, **evaluate** its potential to standardize care practices, and **create** a functional prototype demonstrating its feasibility and effectiveness."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "by9EvAnkSpZf"
      },
      "source": [
        "### Data Description"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jw5LievCSru2"
      },
      "source": [
        "The **Merck Manuals** are medical references published by the American pharmaceutical company Merck & Co., that cover a wide range of medical topics, including disorders, tests, diagnoses, and drugs. The manuals have been published since 1899, when Merck & Co. was still a subsidiary of the German company Merck.\n",
        "\n",
        "The manual is provided as a PDF with over 4,000 pages divided into 23 sections."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnwETBOE6Bz5"
      },
      "source": [
        "## 1 - Installing and Importing Necessary Libraries and Dependencies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4e27b85f"
      },
      "source": [
        "**Set Google Colab to use the T4 GPU**\n",
        "\n",
        "Install `llama-cpp-python` with GPU acceleration. The wheel build is essential; ignore other errors. Then restart runtime."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- `llama-cpp-python` is a Python wrapper for llama.cpp, a universal LLM inference library that runs models efficiently using the GGUF file format.\n",
        "\n",
        "- GGUF (GGML Universal File) is a binary format storing model weights and metadata in a single file. It uses quantization to reduce precision, decreasing memory usage and increasing inference speed.\n",
        "\n",
        "- Model Compatibility: Supports any GGUF-converted model including Llama, Mistral, CodeLlama, Gemma, and Qwen.\n",
        "\n",
        "- `Llama()` class: Main interface for loading and running models\n",
        "\n",
        "- `hf_hub_download()`: A function from the Hugging Face Hub library to download specific files from Hugging Face repositories with automatic caching"
      ],
      "metadata": {
        "id": "z517xAQCqNgA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q4GgLhZhUM4V"
      },
      "outputs": [],
      "source": [
        "# Installation for GPU llama-cpp-python: Downloads and compiles the library with GPU acceleration enabled.\n",
        "!CMAKE_ARGS=\"-DLLAMA_CUBLAS=on\" FORCE_CMAKE=1 pip install llama-cpp-python==0.1.85 --force-reinstall --no-cache-dir -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0VOckDVkWGei"
      },
      "outputs": [],
      "source": [
        "# Install the libraries & downloading models from HF Hub\n",
        "!pip install huggingface_hub pandas tiktoken==0.6.0 pymupdf==1.25.1 langchain==0.3.25 langchain-community==0.3.25 chromadb sentence-transformers numpy -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "RTY9GN4oWK3g"
      },
      "outputs": [],
      "source": [
        "# Libraries for downloading and loading the llm\n",
        "from huggingface_hub import hf_hub_download\n",
        "from llama_cpp import Llama"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TtZWqj0wFTS1"
      },
      "source": [
        "## 2 - Question Answering using LLM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uq1lhM4WFTS2"
      },
      "source": [
        "### 2.1 - Download and load the Mistral model\n",
        "| Model | Repository | File/Name | Model card |\n",
        "|-------|------------|-----------|---------|\n",
        "| Mistral-7B-Instruct-v0.2 | `TheBloke/Mistral-7B-Instruct-v0.2-GGUF` | `mistral-7b-instruct-v0.2.Q6_K.gguf` | https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.2-GGUF |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ONZL0PJNFTS2"
      },
      "outputs": [],
      "source": [
        "# Define the model repository and filename for the Mistral-7B-Instruct-v0.2 GGUF model.\n",
        "model_repo = \"TheBloke/Mistral-7B-Instruct-v0.2-GGUF\"\n",
        "model_file = \"mistral-7b-instruct-v0.2.Q6_K.gguf\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "2Y-lNyJJFTS3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171,
          "referenced_widgets": [
            "0bc07607736c4ecbb0d7c1ab804e9d37",
            "e94ea7080a86449eb24f21c8e8125e4b",
            "5beac6e2d25f49ee93d5289faaede6c2",
            "be18e865d31443208f46a5cbffa89245",
            "852e0324d2cb421aaa522d2b9182391d",
            "cdf1fddbca1a40bc9a1923bff263258e",
            "a5ca764850484bd881da470c800f92e3",
            "310c2d78dd8246c58fb836c8d84a87f3",
            "66e241c6d8f64af0bf9bc3a2cc12e45e",
            "63039d2ca99940168e4f29cfa8f53624",
            "51028c2151014bbba25327361a8ed109"
          ]
        },
        "outputId": "c68097e7-d176-4e24-bae2-44d3c5e2d296"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "mistral-7b-instruct-v0.2.Q6_K.gguf:   0%|          | 0.00/5.94G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0bc07607736c4ecbb0d7c1ab804e9d37"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Download the model\n",
        "model_path = hf_hub_download(\n",
        "    repo_id= model_repo,\n",
        "    filename= model_file\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "rhVkc91BFTS3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09757daa-9e0d-483a-8f94-916686eb3523"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "AVX = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | \n"
          ]
        }
      ],
      "source": [
        "# Initialize the Llama model with the downloaded GGUF file.\n",
        "# model_path: path to the GGUF model file.\n",
        "# n_ctx: context window size (determines how much text the model can process at once).\n",
        "# n_gpu_layers: number of layers to offload to the GPU for acceleration.\n",
        "# n_batch: batch size for processing.\n",
        "llm = Llama(\n",
        "    model_path=model_path,\n",
        "    n_ctx=2300,\n",
        "    n_gpu_layers=38,\n",
        "    n_batch=512\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzzkvIXvFTS4"
      },
      "source": [
        "### 2.2 - Utility function `generate_response`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Ve3UOjcUFTS4"
      },
      "outputs": [],
      "source": [
        "def generate_response(query, max_tokens=128, temperature=0, top_p=0.95, top_k=50, repeat_penalty=1.0):\n",
        "    \"\"\"\n",
        "    Generates a response from the language model.\n",
        "\n",
        "    Args:\n",
        "        query (str): The input prompt for the model.\n",
        "        max_tokens (int, optional): The maximum number of tokens to generate. Defaults to 128.\n",
        "        temperature (float, optional): Controls the randomness of the output. Defaults to 0.\n",
        "        top_p (float, optional): Nucleus sampling parameter. Defaults to 0.95.\n",
        "        top_k (int, optional): Top-k sampling parameter. Defaults to 50.\n",
        "        repeat_penalty (float, optional): Penalizes repeated tokens. Defaults to 1.0.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated text response.\n",
        "    \"\"\"\n",
        "    model_output = llm(\n",
        "            prompt=query,\n",
        "            max_tokens=max_tokens,\n",
        "            temperature=temperature,\n",
        "            top_p=top_p,\n",
        "            top_k=top_k,\n",
        "            repeat_penalty=repeat_penalty\n",
        "        )\n",
        "\n",
        "    return model_output['choices'][0]['text'], model_output"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3 - Querying the LLM"
      ],
      "metadata": {
        "id": "_L6JRcR5AByk"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8YgK91SFjVY"
      },
      "source": [
        "#### Query 1: What is the protocol for managing sepsis in a critical care unit?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "u2Q_QZ4OFjVa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "679e673a-b444-4e44-d5b7-af97c5697d5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Sepsis is a life-threatening condition that can arise from an infection, and it requires prompt recognition and aggressive management in a critical care unit. The following are the general steps for managing sepsis in a critical care unit:\n",
            "\n",
            "1. Early recognition and suspicion: Septic patients may present with non-specific symptoms such as fever, chills, tachycardia, tachypnea, altered mental status, and lactic acidosis. It is essential to have a high index of suspicion for sepsis, especially in patients with known infections or risk factors.\n",
            "2.\n",
            "completion_tokens =  128\n"
          ]
        }
      ],
      "source": [
        "query_1 = \"What is the protocol for managing sepsis in a critical care unit?\"\n",
        "ans_1, moutput_1 = generate_response(query_1)\n",
        "print(ans_1)\n",
        "print(\"completion_tokens = \", moutput_1['usage']['completion_tokens'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6yxICeVFjVc"
      },
      "source": [
        "#### Query 2: What are the common symptoms for appendicitis, and can it be cured via medicine? If not, what surgical procedure should be followed to treat it?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "WO1OTE9CFjVd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e83a6b4b-b304-4352-9369-1318444a7e7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Appendicitis is a medical condition characterized by inflammation of the appendix, a small tube-shaped organ located in the lower right side of the abdomen. The symptoms of appendicitis can vary from person to person, but some common signs include:\n",
            "\n",
            "1. Abdominal pain: The pain is typically located in the lower right side of the abdomen and may start as a mild discomfort that gradually worsens. The pain may be constant or come and go, and it may be accompanied by cramping or bloating.\n",
            "2. Loss of appetite: People with appendic\n",
            "completion_tokens =  128\n"
          ]
        }
      ],
      "source": [
        "query_2 = \"What are the common symptoms of appendicitis, and can it be cured via medicine? If not, what surgical procedure should be followed to treat it?\"\n",
        "ans_2, moutput_2 = generate_response(query_2)\n",
        "print(ans_2)\n",
        "print(\"completion_tokens = \", moutput_2['usage']['completion_tokens'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oflaoOGiFjVd"
      },
      "source": [
        "#### Query 3: What are the effective treatments or solutions for addressing sudden patchy hair loss, commonly seen as localized bald spots on the scalp, and what could be the possible causes behind it?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "JFm5Tq7RFjVe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "895c9c8b-8933-45dd-fd3e-f4d720819418"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Sudden patchy hair loss, also known as alopecia areata, is a common autoimmune disorder that affects the hair follicles, leading to hair loss in small, round patches on the scalp, beard, or other areas of the body. The exact cause of alopecia areata is not known, but it is believed to be related to a problem with the immune system.\n",
            "\n",
            "There are several treatments that have been shown to be effective in addressing sudden patchy hair loss:\n",
            "\n",
            "1. Corticosteroids: Corticosteroids are anti-inflammatory\n",
            "completion_tokens =  128\n"
          ]
        }
      ],
      "source": [
        "query_3 = \"What are the effective treatments or solutions for addressing sudden patchy hair loss, commonly seen as localized bald spots on the scalp, and what could be the possible causes behind it?\"\n",
        "ans_3, moutput_3 = generate_response(query_3)\n",
        "print(ans_3)\n",
        "print(\"completion_tokens = \", moutput_3['usage']['completion_tokens'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUUqY4FbFjVe"
      },
      "source": [
        "#### Query 4:  What treatments are recommended for a person who has sustained a physical injury to brain tissue, resulting in temporary or permanent impairment of brain function?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "DGmG9hYzFjVf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff8877ce-c06d-4cf4-8f58-fa62da959562"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "A person who has sustained a physical injury to brain tissue, resulting in temporary or permanent impairment of brain function, is typically diagnosed with a traumatic brain injury (TBI). The treatment for a TBI depends on the severity and location of the injury, as well as the individual's overall health and age.\n",
            "\n",
            "Immediate treatment for a TBI may include:\n",
            "\n",
            "1. Emergency medical care: This may include surgery to remove hematomas or other obstructions, as well as treatment for other injuries that may have occurred at the same time as the TBI.\n",
            "2. Med\n",
            "completion_tokens =  128\n"
          ]
        }
      ],
      "source": [
        "query_4 = \"What treatments are recommended for a person who has sustained a physical injury to brain tissue, resulting in temporary or permanent impairment of brain function?\"\n",
        "ans_4, moutput_4 = generate_response(query_4)\n",
        "print(ans_4)\n",
        "print(\"completion_tokens = \", moutput_4['usage']['completion_tokens'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5laPFTHrFjVf"
      },
      "source": [
        "#### Query 5: What are the necessary precautions and treatment steps for a person who has fractured their leg during a hiking trip, and what should be considered for their care and recovery?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "NQsR8SplFjVg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a0582ae-f69c-44d7-8811-a7986401ee73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "First and foremost, if a person has fractured their leg during a hiking trip, it is essential to ensure their safety and prevent further injury. Here are some necessary precautions and treatment steps:\n",
            "\n",
            "1. Assess the situation: Check the extent of the injury and assess the person's condition. If the fracture is open or the person is in severe pain, immobilize the leg with a splint or a makeshift sling to prevent any movement.\n",
            "2. Call for help: If possible, call for emergency medical assistance. If there is no cell phone reception, try to\n",
            "completion_tokens =  128\n"
          ]
        }
      ],
      "source": [
        "query_5 = \"What are the necessary precautions and treatment steps for a person who has fractured their leg during a hiking trip, and what should be considered for their care and recovery?\"\n",
        "ans_5, moutput_5 = generate_response(query_5)\n",
        "print(ans_5)\n",
        "print(\"completion_tokens = \", moutput_5['usage']['completion_tokens'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "510748d8"
      },
      "source": [
        "<span style=\"color: blue;\"> **Observation**</span>\n",
        "- The responses to the questions are generic.\n",
        "- The output is truncated due to the default `max_tokens` limit of 128."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5myZ5dOOefc"
      },
      "source": [
        "## 3 - Question Answering using LLM with Prompt Engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VMZqTudYBCWv"
      },
      "outputs": [],
      "source": [
        "system_prompt = \"_____\" #Complete the code to define the system prompt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Jg3r_LWOeff"
      },
      "source": [
        "### Query 1: What is the protocol for managing sepsis in a critical care unit?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O5zh3HQoOeff"
      },
      "outputs": [],
      "source": [
        "user_input = system_prompt+\"\\n\"+ \"What is the protocol for managing sepsis in a critical care unit?\"\n",
        "response(user_input)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYpyw4HjOeff"
      },
      "source": [
        "### Query 2: What are the common symptoms for appendicitis, and can it be cured via medicine? If not, what surgical procedure should be followed to treat it?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WPPpDM6cOeff"
      },
      "outputs": [],
      "source": [
        "user_input = _____ #Complete the code to pass the query #2\n",
        "response(_____) #Complete the code to pass the user input"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dRp92JQZOeff"
      },
      "source": [
        "### Query 3: What are the effective treatments or solutions for addressing sudden patchy hair loss, commonly seen as localized bald spots on the scalp, and what could be the possible causes behind it?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sC6rrtblOefg"
      },
      "outputs": [],
      "source": [
        "user_input = _____ #Complete the code to pass the query #3\n",
        "response(_____) #Complete the code to pass the user input"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AA45zwyUOefg"
      },
      "source": [
        "### Query 4:  What treatments are recommended for a person who has sustained a physical injury to brain tissue, resulting in temporary or permanent impairment of brain function?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3DrjIlKlOefg"
      },
      "outputs": [],
      "source": [
        "user_input = _____ #Complete the code to pass the query #4\n",
        "response(_____) #Complete the code to pass the user input"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYXxiSuBOefg"
      },
      "source": [
        "### Query 5: What are the necessary precautions and treatment steps for a person who has fractured their leg during a hiking trip, and what should be considered for their care and recovery?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ue8Lk8uXOefg"
      },
      "outputs": [],
      "source": [
        "user_input = _____ #Complete the code to pass the query #5\n",
        "response(_____) #Complete the code to pass the user input"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_O1PGdNO2M9"
      },
      "source": [
        "## 4 - Data Preparation for RAG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7f4yFqLBINGG"
      },
      "outputs": [],
      "source": [
        "#Libraries for processing dataframes,text\n",
        "import json,os\n",
        "import tiktoken\n",
        "import pandas as pd\n",
        "\n",
        "#Libraries for Loading Data, Chunking, Embedding, and Vector Databases\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.document_loaders import PyMuPDFLoader\n",
        "from langchain_community.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
        "from langchain_community.vectorstores import Chroma"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTpWESc53dL9"
      },
      "source": [
        "### Loading the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a5dLjPsyi1A4"
      },
      "outputs": [],
      "source": [
        "# uncomment and run the below code snippets if the dataset is present in the Google Drive\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ksv9hSCR4BM_"
      },
      "outputs": [],
      "source": [
        "manual_pdf_path = \"_____\" #Complete the code to define the file name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jhf34I1eYNtR"
      },
      "outputs": [],
      "source": [
        "pdf_loader = PyMuPDFLoader(manual_pdf_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YChLS31TxC3-"
      },
      "outputs": [],
      "source": [
        "manual = pdf_loader.load()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffj0ca3eZT4u"
      },
      "source": [
        "### Data Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9weTDzMxRRS"
      },
      "source": [
        "#### Checking the first 5 pages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JSOv3q2pxX4z"
      },
      "outputs": [],
      "source": [
        "for i in range(5):\n",
        "    print(f\"Page Number : {i+1}\",end=\"\\n\")\n",
        "    print(manual[i].page_content,end=\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-wNNalNxPKT"
      },
      "source": [
        "#### Checking the number of pages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "scMnmNKtxBea"
      },
      "outputs": [],
      "source": [
        "len(manual)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LECMxTH-zB-R"
      },
      "source": [
        "### Data Chunking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uG0_pBmizGGt"
      },
      "outputs": [],
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
        "    encoding_name='cl100k_base',\n",
        "    chunk_size=_____, #Complete the code to define the chunk size\n",
        "    chunk_overlap= _____ #Complete the code to define the chunk overlap\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w76ji7ECzLLQ"
      },
      "outputs": [],
      "source": [
        "document_chunks = pdf_loader.load_and_split(text_splitter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i6TQ-mmLzR9I"
      },
      "outputs": [],
      "source": [
        "len(document_chunks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DuRoMIGNzZaJ"
      },
      "outputs": [],
      "source": [
        "document_chunks[0].page_content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9xAQYLXqyCc6"
      },
      "outputs": [],
      "source": [
        "document_chunks[2].page_content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ju4gtXwiyILp"
      },
      "outputs": [],
      "source": [
        "document_chunks[3].page_content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yl_9lAlGaYdf"
      },
      "source": [
        "As expected, there are some overlaps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BvHVejcWz0Bl"
      },
      "source": [
        "### Embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c6cZVZWQz15c"
      },
      "outputs": [],
      "source": [
        "embedding_model = SentenceTransformerEmbeddings(model_name=\"_____\") #Complete the code to define the model name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dvc-CTtCz4kJ"
      },
      "outputs": [],
      "source": [
        "embedding_1 = embedding_model.embed_query(document_chunks[0].page_content)\n",
        "embedding_2 = embedding_model.embed_query(document_chunks[1].page_content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W0qy6xOZ0UBe"
      },
      "outputs": [],
      "source": [
        "print(\"Dimension of the embedding vector \",len(embedding_1))\n",
        "len(embedding_1)==len(embedding_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1bmtFRTN0VtN"
      },
      "outputs": [],
      "source": [
        "embedding_1,embedding_2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qiKCOv4X0d7B"
      },
      "source": [
        "### Vector Database"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NWOqhGMV0kZ9"
      },
      "outputs": [],
      "source": [
        "out_dir = 'medical_db'\n",
        "\n",
        "if not os.path.exists(out_dir):\n",
        "  os.makedirs(out_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8g-D3URW0iEO"
      },
      "outputs": [],
      "source": [
        "vectorstore = Chroma.from_documents(\n",
        "    _____, #Complete the code to pass the document chunks\n",
        "    _____, #Complete the code to pass the embedding model\n",
        "    persist_directory=out_dir\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SuK6hsbaGfqH"
      },
      "outputs": [],
      "source": [
        "vectorstore = Chroma(persist_directory=out_dir,embedding_function=embedding_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GdZON_Uj1EeS"
      },
      "outputs": [],
      "source": [
        "vectorstore.embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P9HgsipF1I4H"
      },
      "outputs": [],
      "source": [
        "vectorstore.similarity_search(\"_____\",k=_____) #Complete the code to pass a query and an appropriate k value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uEa5sKc41T1z"
      },
      "source": [
        "### Retriever"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zO5kmp381VsX"
      },
      "outputs": [],
      "source": [
        "retriever = vectorstore.as_retriever(\n",
        "    search_type='similarity',\n",
        "    search_kwargs={'k': _____} #Complete the code to pass an appropriate k value\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bnKuqfWB1gBx"
      },
      "outputs": [],
      "source": [
        "rel_docs = retriever.get_relevant_documents(\"_____\") #Complete the code to pass the query\n",
        "rel_docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yjLbgBH83iQ6"
      },
      "outputs": [],
      "source": [
        "model_output = llm(\n",
        "      \"_____\", #Complete the code to pass the query\n",
        "      max_tokens=_____, #Complete the code to pass the maximum number of tokens\n",
        "      temperature=_____, #Complete the code to pass the temperature\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p9K5_CD23zFY"
      },
      "outputs": [],
      "source": [
        "model_output['choices'][0]['text']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YADTleB324vl"
      },
      "source": [
        "The above response is somewhat generic and is solely based on the data the model was trained on, rather than the medical manual.  \n",
        "\n",
        "Let's now provide our own context."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vw8qcwq66B0C",
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### System and User Prompt Template"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wRkZYtO6B0D"
      },
      "source": [
        "Prompts guide the model to generate accurate responses. Here, we define two parts:\n",
        "\n",
        "    1. The system message describing the assistant's role.\n",
        "    2. A user message template including context and the question."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1737358838889
        },
        "id": "Dyl60SEs6B0D",
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "qna_system_message = \"_____\"  #Complete the code to define the system message"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XW38rWoNjJkQ"
      },
      "outputs": [],
      "source": [
        "qna_user_message_template = \"_____\" #Complete the code to define the user message"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TkIteX4m6mny"
      },
      "source": [
        "### Response Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J-SfCZqC6B0E",
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "def generate_rag_response(user_input,k=3,max_tokens=128,temperature=0,top_p=0.95,top_k=50):\n",
        "    global qna_system_message,qna_user_message_template\n",
        "    # Retrieve relevant document chunks\n",
        "    relevant_document_chunks = retriever.get_relevant_documents(query=user_input,k=k)\n",
        "    context_list = [d.page_content for d in relevant_document_chunks]\n",
        "\n",
        "    # Combine document chunks into a single context\n",
        "    context_for_query = \". \".join(context_list)\n",
        "\n",
        "    user_message = qna_user_message_template.replace('{context}', context_for_query)\n",
        "    user_message = user_message.replace('{question}', user_input)\n",
        "\n",
        "    prompt = qna_system_message + '\\n' + user_message\n",
        "\n",
        "    # Generate the response\n",
        "    try:\n",
        "        response = llm(\n",
        "                  prompt=prompt,\n",
        "                  max_tokens=max_tokens,\n",
        "                  temperature=temperature,\n",
        "                  top_p=top_p,\n",
        "                  top_k=top_k\n",
        "                  )\n",
        "\n",
        "        # Extract and print the model's response\n",
        "        response = response['choices'][0]['text'].strip()\n",
        "    except Exception as e:\n",
        "        response = f'Sorry, I encountered the following error: \\n {e}'\n",
        "\n",
        "    return response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffP1SRYbPQHN"
      },
      "source": [
        "## 5 - Question Answering using RAG"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjajBEj06B0E"
      },
      "source": [
        "### Query 1: What is the protocol for managing sepsis in a critical care unit?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gt4TAQNa6B0E"
      },
      "outputs": [],
      "source": [
        "user_input = \"What is the protocol for managing sepsis in a critical care unit?\"\n",
        "generate_rag_response(user_input,top_k=20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDw8zXuq6B0F"
      },
      "source": [
        "### Query 2: What are the common symptoms for appendicitis, and can it be cured via medicine? If not, what surgical procedure should be followed to treat it?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i92cv0dQ6B0F"
      },
      "outputs": [],
      "source": [
        "user_input_2 = \"_____\" #Complete the code to pass the query #2\n",
        "generate_rag_response(_____) #Complete the code to pass the user input"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TggYyQPL6B0G"
      },
      "source": [
        "### Query 3: What are the effective treatments or solutions for addressing sudden patchy hair loss, commonly seen as localized bald spots on the scalp, and what could be the possible causes behind it?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ed6x6LGb6B0G"
      },
      "outputs": [],
      "source": [
        "user_input_2 = \"_____\" #Complete the code to pass the query #3\n",
        "generate_rag_response(_____) #Complete the code to pass the user input"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1TgxdI-_6B0G"
      },
      "source": [
        "### Query 4:  What treatments are recommended for a person who has sustained a physical injury to brain tissue, resulting in temporary or permanent impairment of brain function?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u7ru57_c6B0G"
      },
      "outputs": [],
      "source": [
        "user_input_2 = \"_____\" #Complete the code to pass the query #4\n",
        "generate_rag_response(_____) #Complete the code to pass the user input"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlHXYCkm6B0H"
      },
      "source": [
        "### Query 5: What are the necessary precautions and treatment steps for a person who has fractured their leg during a hiking trip, and what should be considered for their care and recovery?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LYIbiI_P6B0H"
      },
      "outputs": [],
      "source": [
        "user_input_2 = \"_____\" #Complete the code to pass the query #5\n",
        "generate_rag_response(_____) #Complete the code to pass the user input"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7TYrqycEITB"
      },
      "source": [
        "### Fine-tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqPMPTQLUxel"
      },
      "source": [
        "#### Query 1: What is the protocol for managing sepsis in a critical care unit?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oIW5A_6rUxeo"
      },
      "outputs": [],
      "source": [
        "user_input = \"What is the protocol for managing sepsis in a critical care unit?\"\n",
        "generate_rag_response(user_input,temperature=0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lP8LwnbUxep"
      },
      "source": [
        "#### Query 2: What are the common symptoms for appendicitis, and can it be cured via medicine? If not, what surgical procedure should be followed to treat it?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "99zlqRbvUxeq"
      },
      "outputs": [],
      "source": [
        "user_input_2 = \"_____\" #Complete the code to pass the query #2\n",
        "generate_rag_response(_____) #Complete the code to pass the user input along with the parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pludvG5BUxer"
      },
      "source": [
        "#### Query 3: What are the effective treatments or solutions for addressing sudden patchy hair loss, commonly seen as localized bald spots on the scalp, and what could be the possible causes behind it?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9CTt5MqmUxes"
      },
      "outputs": [],
      "source": [
        "user_input_2 = \"_____\" #Complete the code to pass the query #3\n",
        "generate_rag_response(_____) #Complete the code to pass the user input along with the parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydSZJlJQUxes"
      },
      "source": [
        "#### Query 4:  What treatments are recommended for a person who has sustained a physical injury to brain tissue, resulting in temporary or permanent impairment of brain function?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Pn3DJaUUxet"
      },
      "outputs": [],
      "source": [
        "user_input_2 = \"_____\" #Complete the code to pass the query #4\n",
        "generate_rag_response(_____) #Complete the code to pass the user input along with the parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hAVjKHMUxeu"
      },
      "source": [
        "#### Query 5: What are the necessary precautions and treatment steps for a person who has fractured their leg during a hiking trip, and what should be considered for their care and recovery?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QD1T75NZUxev"
      },
      "outputs": [],
      "source": [
        "user_input_2 = \"_____\" #Complete the code to pass the query #5\n",
        "generate_rag_response(_____) #Complete the code to pass the user input along with the parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yyQrTipNfuBN"
      },
      "source": [
        "## 6 - Output Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HbXMSxqa-65E"
      },
      "source": [
        "Let us now use the LLM-as-a-judge method to check the quality of the RAG system on two parameters - retrieval and generation.\n",
        "\n",
        "- We are using the same Mistral model for evaluation, so basically here the llm is rating itself on how well he has performed in the task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2dDxkZdyKSnh",
        "tags": []
      },
      "outputs": [],
      "source": [
        "groundedness_rater_system_message = \"_____\" #Complete the code to define the prompt to evaluate groundedness"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NIosu2Wk7OVs",
        "tags": []
      },
      "outputs": [],
      "source": [
        "relevance_rater_system_message = \"_____\" #Complete the code to define the prompt to evaluate relevance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7boMupgh_Gux",
        "tags": []
      },
      "outputs": [],
      "source": [
        "user_message_template = \"\"\"\n",
        "###Question\n",
        "{question}\n",
        "\n",
        "###Context\n",
        "{context}\n",
        "\n",
        "###Answer\n",
        "{answer}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q9UVEOZbXYlh"
      },
      "outputs": [],
      "source": [
        "def generate_ground_relevance_response(user_input,k=3,max_tokens=128,temperature=0,top_p=0.95,top_k=50):\n",
        "    global qna_system_message,qna_user_message_template\n",
        "    # Retrieve relevant document chunks\n",
        "    relevant_document_chunks = retriever.get_relevant_documents(query=user_input,k=3)\n",
        "    context_list = [d.page_content for d in relevant_document_chunks]\n",
        "    context_for_query = \". \".join(context_list)\n",
        "\n",
        "    # Combine user_prompt and system_message to create the prompt\n",
        "    prompt = f\"\"\"[INST]{qna_system_message}\\n\n",
        "                {'user'}: {qna_user_message_template.format(context=context_for_query, question=user_input)}\n",
        "                [/INST]\"\"\"\n",
        "\n",
        "    response = llm(\n",
        "            prompt=prompt,\n",
        "            max_tokens=max_tokens,\n",
        "            temperature=temperature,\n",
        "            top_p=top_p,\n",
        "            top_k=top_k,\n",
        "            stop=['INST'],\n",
        "            echo=False\n",
        "            )\n",
        "\n",
        "    answer =  response[\"choices\"][0][\"text\"]\n",
        "\n",
        "    # Combine user_prompt and system_message to create the prompt\n",
        "    groundedness_prompt = f\"\"\"[INST]{groundedness_rater_system_message}\\n\n",
        "                {'user'}: {user_message_template.format(context=context_for_query, question=user_input, answer=answer)}\n",
        "                [/INST]\"\"\"\n",
        "\n",
        "    # Combine user_prompt and system_message to create the prompt\n",
        "    relevance_prompt = f\"\"\"[INST]{relevance_rater_system_message}\\n\n",
        "                {'user'}: {user_message_template.format(context=context_for_query, question=user_input, answer=answer)}\n",
        "                [/INST]\"\"\"\n",
        "\n",
        "    response_1 = llm(\n",
        "            prompt=groundedness_prompt,\n",
        "            max_tokens=max_tokens,\n",
        "            temperature=temperature,\n",
        "            top_p=top_p,\n",
        "            top_k=top_k,\n",
        "            stop=['INST'],\n",
        "            echo=False\n",
        "            )\n",
        "\n",
        "    response_2 = llm(\n",
        "            prompt=relevance_prompt,\n",
        "            max_tokens=max_tokens,\n",
        "            temperature=temperature,\n",
        "            top_p=top_p,\n",
        "            top_k=top_k,\n",
        "            stop=['INST'],\n",
        "            echo=False\n",
        "            )\n",
        "\n",
        "    return response_1['choices'][0]['text'],response_2['choices'][0]['text']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6qxqyJLYA2x"
      },
      "source": [
        "### Query 1: What is the protocol for managing sepsis in a critical care unit?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ANzurSjuYA2x"
      },
      "outputs": [],
      "source": [
        "ground,rel = generate_ground_relevance_response(user_input=\"What is the protocol for managing sepsis in a critical care unit?\",max_tokens=370)\n",
        "\n",
        "print(ground,end=\"\\n\\n\")\n",
        "print(rel)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7A60Q6x3YA2y"
      },
      "source": [
        "### Query 2: What are the common symptoms for appendicitis, and can it be cured via medicine? If not, what surgical procedure should be followed to treat it?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LOZQyoLwYA2y"
      },
      "outputs": [],
      "source": [
        "ground,rel = generate_ground_relevance_response(user_input=\"_____\",_____) #Complete the code to pass the query #2 along with parameters if needed\n",
        "\n",
        "print(ground,end=\"\\n\\n\")\n",
        "print(rel)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZmYnriTdYA2z"
      },
      "source": [
        "### Query 3: What are the effective treatments or solutions for addressing sudden patchy hair loss, commonly seen as localized bald spots on the scalp, and what could be the possible causes behind it?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qp898M2iYA2z"
      },
      "outputs": [],
      "source": [
        "ground,rel = generate_ground_relevance_response(user_input=\"_____\",_____) #Complete the code to pass the query #3 along with parameters if needed\n",
        "\n",
        "print(ground,end=\"\\n\\n\")\n",
        "print(rel)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jz-lGsVxYA2z"
      },
      "source": [
        "### Query 4: What treatments are recommended for a person who has sustained a physical injury to brain tissue, resulting in temporary or permanent impairment of brain function?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gBRTYnFVYA2z"
      },
      "outputs": [],
      "source": [
        "ground,rel = generate_ground_relevance_response(user_input=\"_____\",_____) #Complete the code to pass the query #4 along with parameters if needed\n",
        "\n",
        "print(ground,end=\"\\n\\n\")\n",
        "print(rel)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2WxSxzDYA2z"
      },
      "source": [
        "### Query 5: What are the necessary precautions and treatment steps for a person who has fractured their leg during a hiking trip, and what should be considered for their care and recovery?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mKCq09_YYA20"
      },
      "outputs": [],
      "source": [
        "ground,rel = generate_ground_relevance_response(user_input=\"_____\",_____) #Complete the code to pass the query #5 along with parameters if needed\n",
        "\n",
        "print(ground,end=\"\\n\\n\")\n",
        "print(rel)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7QICRU-njdj"
      },
      "source": [
        "## Actionable Insights and Business Recommendations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObyXYhOojIaY"
      },
      "source": [
        "\n",
        "*   \n",
        "*  \n",
        "*\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybRlzaIhWaM9"
      },
      "source": [
        "<font size=6 color='blue'>Power Ahead</font>\n",
        "___"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "3CNz35ia6Bz3",
        "CkRbhMJH6Bz3",
        "CARPKFwm6Bz4",
        "by9EvAnkSpZf",
        "Uq1lhM4WFTS2",
        "EzzkvIXvFTS4",
        "K8YgK91SFjVY",
        "J6yxICeVFjVc",
        "oflaoOGiFjVd",
        "WUUqY4FbFjVe",
        "5laPFTHrFjVf",
        "9Jg3r_LWOeff",
        "iYpyw4HjOeff",
        "dRp92JQZOeff",
        "AA45zwyUOefg",
        "TYXxiSuBOefg",
        "t_O1PGdNO2M9",
        "ffj0ca3eZT4u",
        "f9weTDzMxRRS",
        "7-wNNalNxPKT",
        "LECMxTH-zB-R",
        "BvHVejcWz0Bl",
        "qiKCOv4X0d7B",
        "uEa5sKc41T1z",
        "vw8qcwq66B0C",
        "TkIteX4m6mny",
        "ffP1SRYbPQHN",
        "JjajBEj06B0E",
        "QDw8zXuq6B0F",
        "TggYyQPL6B0G",
        "1TgxdI-_6B0G",
        "FlHXYCkm6B0H",
        "K7TYrqycEITB",
        "rqPMPTQLUxel",
        "1lP8LwnbUxep",
        "pludvG5BUxer",
        "ydSZJlJQUxes",
        "5hAVjKHMUxeu",
        "f6qxqyJLYA2x",
        "7A60Q6x3YA2y",
        "ZmYnriTdYA2z",
        "jz-lGsVxYA2z",
        "x2WxSxzDYA2z",
        "Y7QICRU-njdj"
      ],
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0bc07607736c4ecbb0d7c1ab804e9d37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e94ea7080a86449eb24f21c8e8125e4b",
              "IPY_MODEL_5beac6e2d25f49ee93d5289faaede6c2",
              "IPY_MODEL_be18e865d31443208f46a5cbffa89245"
            ],
            "layout": "IPY_MODEL_852e0324d2cb421aaa522d2b9182391d"
          }
        },
        "e94ea7080a86449eb24f21c8e8125e4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cdf1fddbca1a40bc9a1923bff263258e",
            "placeholder": "",
            "style": "IPY_MODEL_a5ca764850484bd881da470c800f92e3",
            "value": "mistral-7b-instruct-v0.2.Q6_K.gguf:100%"
          }
        },
        "5beac6e2d25f49ee93d5289faaede6c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_310c2d78dd8246c58fb836c8d84a87f3",
            "max": 5942065440,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_66e241c6d8f64af0bf9bc3a2cc12e45e",
            "value": 5942065440
          }
        },
        "be18e865d31443208f46a5cbffa89245": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_63039d2ca99940168e4f29cfa8f53624",
            "placeholder": "",
            "style": "IPY_MODEL_51028c2151014bbba25327361a8ed109",
            "value": "5.94G/5.94G[01:37&lt;00:00,221MB/s]"
          }
        },
        "852e0324d2cb421aaa522d2b9182391d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cdf1fddbca1a40bc9a1923bff263258e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5ca764850484bd881da470c800f92e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "310c2d78dd8246c58fb836c8d84a87f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66e241c6d8f64af0bf9bc3a2cc12e45e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "63039d2ca99940168e4f29cfa8f53624": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51028c2151014bbba25327361a8ed109": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}